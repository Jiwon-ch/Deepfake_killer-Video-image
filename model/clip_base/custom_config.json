{
  "model_type": "unified_adapter",
  "clip_model_name": "openai/clip-vit-large-patch14",
  "num_frames": 12,
  "adapter_type": "tconv",
  "temporal_pool": "mean",
  "head_hidden": 1024,
  "num_classes": 2,
  "id2label": {
    "0": "real",
    "1": "fake"
  },
  "label2id": {
    "real": 0,
    "fake": 1
  }
}